{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mike/corrcal_gpu_pipeline is already in sys.path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    print(f\"Added {parent_dir} to sys.path\")\n",
    "else:\n",
    "    print(f\"{parent_dir} is already in sys.path\")\n",
    "    \n",
    "from pipeline.invcov import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Tests for Covariance Inverse Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edges of the redundant blocks have indices[    0  1452  1631  1944  2111  2757  5045  5592  5955  6095  8922 10000]\n",
      "Time on cpu: 0.029400s\n",
      "Time on gpu: 0.029451s\n"
     ]
    }
   ],
   "source": [
    "#the main parametes describing our problem.\n",
    "n_bl = 10000\n",
    "n_eig = 3\n",
    "n_src = 6\n",
    "xp = cp  #run things on the gpu using cupy\n",
    "\n",
    "#random array of edges for the diffuse matrix\n",
    "edges = xp.unique(xp.random.randint(1, n_bl-1, size = 10))\n",
    "edges = xp.concatenate((xp.array([0]), edges, xp.array([n_bl])))\n",
    "print(f\"The edges of the redundant blocks have indices{edges}\")\n",
    "\n",
    "#some random noise, diffuse, and source covariance matrices\n",
    "sim_noise_mat = xp.random.rand(n_bl)**2   #in principle this is squared since is a variance\n",
    "sim_diff_mat = xp.random.rand(n_bl, n_eig)\n",
    "sim_src_mat = xp.random.rand(n_bl, n_src)\n",
    "\n",
    "#perform cupy benchmark\n",
    "test_results = str(benchmark(inverse_covariance, (sim_noise_mat, sim_diff_mat, sim_src_mat, edges, xp), n_repeat=100))\n",
    "test_results = test_results.split()\n",
    "cpu_t = float(test_results[3])/1e6\n",
    "gpu_t = float(test_results[14])/1e6\n",
    "print(f\"Time on cpu: {cpu_t:.6f}s\")\n",
    "print(f\"Time on gpu: {gpu_t:.6f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cpu = 0.0086\n",
    "\n",
    "gpu = 0.0091\n",
    "\n",
    "cpu = 0.026\n",
    "\n",
    "gpu = 0.026\n",
    "\n",
    "Seems to run ***way*** faster using numpy and thus on the cpu. Need to figure out why this is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is veery rough work trying to understand why the time differs in the way it does between the cpu and the gpu ... \n",
    "\n",
    "Update: Turns out to be the zeropad function which we will work on elsewhere "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU execution time: 0.015513s\n",
      "GPU execution time: 0.040890s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Function to time the execution\n",
    "def time_function(func, *args):\n",
    "    start_time = time.time()\n",
    "    func(*args)\n",
    "    return time.time() - start_time\n",
    "\n",
    "# Timing CPU execution\n",
    "xp = np\n",
    "edges = xp.unique(xp.random.randint(1, n_bl-1, size = 10))\n",
    "edges = xp.concatenate((xp.array([0]), edges, xp.array([n_bl])))\n",
    "sim_noise_mat = xp.random.rand(n_bl)**2\n",
    "sim_diff_mat = xp.random.rand(n_bl, n_eig)\n",
    "sim_src_mat = xp.random.rand(n_bl, n_src)\n",
    "cpu_time = time_function(inverse_covariance, sim_noise_mat, sim_diff_mat, sim_src_mat, edges, xp)\n",
    "print(f\"CPU execution time: {cpu_time:.6f}s\")\n",
    "\n",
    "# Timing GPU execution\n",
    "xp = cp\n",
    "edges = xp.unique(xp.random.randint(1, n_bl-1, size = 10))\n",
    "edges = xp.concatenate((xp.array([0]), edges, xp.array([n_bl])))\n",
    "sim_noise_mat = xp.random.rand(n_bl)**2\n",
    "sim_diff_mat = xp.random.rand(n_bl, n_eig)\n",
    "sim_src_mat = xp.random.rand(n_bl, n_src)\n",
    "gpu_time = time_function(inverse_covariance, sim_noise_mat, sim_diff_mat, sim_src_mat, edges, xp)\n",
    "print(f\"GPU execution time: {gpu_time:.6f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transfer time: 0.001188s\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "def transfer_and_time(xp, *arrays):\n",
    "    start = time.time()\n",
    "    arrays = [xp.asarray(arr) for arr in arrays]\n",
    "    transfer_time = time.time() - start\n",
    "    return transfer_time, arrays\n",
    "\n",
    "# Measure transfer time\n",
    "edges = np.unique(np.random.randint(1, n_bl-1, size = 10))\n",
    "edges = np.concatenate((np.array([0]), edges, np.array([n_bl])))\n",
    "transfer_time, (sim_noise_mat, sim_diff_mat, sim_src_mat) = transfer_and_time(cp, \n",
    "    np.random.rand(n_bl)**2, \n",
    "    np.random.rand(n_bl, n_eig), \n",
    "    np.random.rand(n_bl, n_src)\n",
    ")\n",
    "print(f\"Data transfer time: {transfer_time:.6f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time on CPU: 0.008077s\n",
      "Time on GPU: 0.008838s\n"
     ]
    }
   ],
   "source": [
    "from cupyx.profiler import benchmark\n",
    "\n",
    "def benchmark_inverse_covariance():\n",
    "    result = str(benchmark(inverse_covariance, (sim_noise_mat, sim_diff_mat, sim_src_mat, edges, cp), n_repeat=10))\n",
    "    result = result.split()\n",
    "    cpu_t = float(result[3]) / 1e6\n",
    "    gpu_t = float(result[14]) / 1e6\n",
    "    print(f\"Time on CPU: {cpu_t:.6f}s\")\n",
    "    print(f\"Time on GPU: {gpu_t:.6f}s\")\n",
    "\n",
    "benchmark_inverse_covariance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "def matmul(A, B, xp):\n",
    "    result = xp.zeros((A.shape[0], B.shape[1]))\n",
    "    for row in range(A.shape[0]):\n",
    "        for col in range(B.shape[1]):\n",
    "            for k in range(B.shape[0]):\n",
    "                result[row, col] += A[row, k]*B[k, col] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = np\n",
    "A = xp.random.rand(100, 100)\n",
    "B = xp.random.rand(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time on CPU: 0.519882s\n",
      "Time on GPU: 0.520570s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = str(benchmark(matmul, (A, B, xp), n_repeat=100))\n",
    "result = result.split()\n",
    "cpu_t = float(result[3]) / 1e6\n",
    "gpu_t = float(result[14]) / 1e6\n",
    "print(f\"Time on CPU: {cpu_t:.6f}s\")\n",
    "print(f\"Time on GPU: {gpu_t:.6f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edges of the redundant blocks have indices[     0  17085  21441  45378  47595  55542  78711  79842  91981 100375\n",
      " 111125 120000]\n",
      "Time on CPU: 0.000737s\n",
      "Time on GPU: 0.000862s\n"
     ]
    }
   ],
   "source": [
    "#let's benchmark the zeropad functions\n",
    "\n",
    "#the main parametes describing our problem.\n",
    "n_bl = 120000\n",
    "n_eig = 3\n",
    "n_src = 5\n",
    "xp = np  #run things on the gpu using cupy\n",
    "\n",
    "#random array of edges for the diffuse matrix\n",
    "edges = xp.unique(xp.random.randint(1, n_bl-1, size = 10))\n",
    "edges = xp.concatenate((xp.array([0]), edges, xp.array([n_bl])))\n",
    "print(f\"The edges of the redundant blocks have indices{edges}\")\n",
    "\n",
    "#some random noise, diffuse, and source covariance matrices\n",
    "sim_noise_mat = xp.random.rand(n_bl)**2   #in principle this is squared since is a variance\n",
    "sim_diff_mat = xp.random.rand(n_bl, n_eig)\n",
    "sim_src_mat = xp.random.rand(n_bl, n_src)\n",
    "\n",
    "\n",
    "result = str(benchmark(zeropad, (sim_diff_mat, edges, xp), n_repeat=10000))\n",
    "result = result.split()\n",
    "cpu_t = float(result[3]) / 1e6\n",
    "gpu_t = float(result[14]) / 1e6\n",
    "print(f\"Time on CPU: {cpu_t:.6f}s\")\n",
    "print(f\"Time on GPU: {gpu_t:.6f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "# Define the CUDA kernel for zero-padding\n",
    "zeropad_kernel = cp.RawKernel(r'''\n",
    "extern \"C\" __global__\n",
    "void zeropad(const int* edges, const float* array, float* out, int n_blocks, int largest_block, int array_width) {\n",
    "    int block_idx = blockIdx.x;\n",
    "    int thread_idx = threadIdx.x;\n",
    "    int start = edges[block_idx];\n",
    "    int stop = edges[block_idx + 1];\n",
    "    int offset = block_idx * largest_block;\n",
    "\n",
    "    if (thread_idx < (stop - start)) {\n",
    "        out[offset + thread_idx] = array[start + thread_idx];\n",
    "    }\n",
    "}\n",
    "''', 'zeropad')\n",
    "\n",
    "def zeropad_cuda(array, edges, xp):\n",
    "    edges = xp.asarray(edges, dtype=cp.int32)\n",
    "    array = xp.asarray(array, dtype=cp.float32)\n",
    "    \n",
    "    largest_block = xp.diff(edges).max()\n",
    "    n_blocks = edges.size - 1\n",
    "\n",
    "    if array.ndim == 1:  # should only be the case for the noise matrix\n",
    "        out = xp.zeros((n_blocks, int(largest_block)), dtype=cp.float32)\n",
    "    else:\n",
    "        out = xp.zeros((n_blocks, int(largest_block), int(array.shape[1])), dtype=cp.float32)\n",
    "\n",
    "    # Launch the kernel\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = n_blocks\n",
    "\n",
    "    if array.ndim == 1:\n",
    "        zeropad_kernel((blocks_per_grid,), (threads_per_block,), \n",
    "                       (edges, array, out, n_blocks, int(largest_block), 0))\n",
    "    else:\n",
    "        for i in range(array.shape[1]):\n",
    "            zeropad_kernel((blocks_per_grid,), (threads_per_block,), \n",
    "                           (edges, array[:, i], out[:, :, i], n_blocks, int(largest_block), array.shape[1]))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edges of the redundant blocks have indices[ 0  1  2  3  4  5  6  8 10]\n",
      "Time on CPU: 0.001146s\n",
      "Time on GPU: 0.001166s\n"
     ]
    }
   ],
   "source": [
    "#the main parametes describing our problem.\n",
    "n_bl = 10\n",
    "n_eig = 3\n",
    "n_src = 5\n",
    "xp = cp  #run things on the gpu using cupy\n",
    "\n",
    "#random array of edges for the diffuse matrix\n",
    "edges = xp.unique(xp.random.randint(1, n_bl-1, size = 10))\n",
    "edges = xp.concatenate((xp.array([0]), edges, xp.array([n_bl])))\n",
    "print(f\"The edges of the redundant blocks have indices{edges}\")\n",
    "\n",
    "#some random noise, diffuse, and source covariance matrices\n",
    "sim_noise_mat = xp.random.rand(n_bl)**2   #in principle this is squared since is a variance\n",
    "sim_diff_mat = xp.random.rand(n_bl, n_eig)\n",
    "sim_src_mat = xp.random.rand(n_bl, n_src)\n",
    "\n",
    "\n",
    "result = str(benchmark(zeropad_cuda, (sim_diff_mat, edges, xp), n_repeat=10000))\n",
    "result = result.split()\n",
    "cpu_t = float(result[3]) / 1e6\n",
    "gpu_t = float(result[14]) / 1e6\n",
    "print(f\"Time on CPU: {cpu_t:.6f}s\")\n",
    "print(f\"Time on GPU: {gpu_t:.6f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.31668377 0.9918387  0.05347418]\n",
      "  [0.05347418 0.6461567  0.6461567 ]]\n",
      "\n",
      " [[0.5948217  0.5948217  0.20444898]\n",
      "  [0.20444898 0.28285316 0.28285316]]\n",
      "\n",
      " [[0.56092954 0.56092954 0.84872013]\n",
      "  [0.581425   0.9728917  0.7077299 ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(zeropad_cuda(sim_diff_mat, edges, cp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
